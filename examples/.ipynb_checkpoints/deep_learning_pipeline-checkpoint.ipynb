{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db09931f-39e8-446d-bb79-dc1627958b80",
   "metadata": {},
   "source": [
    "# Deep Learning Preprocessing Pipeline\n",
    "\n",
    "In this tutorial, we are going to build a data preprocessing pipeline which is destined to be fed into a LSTM neural network, which is often used when dealing with time series. Learn more about LSTM neural networks here: https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "As a data source for our pipeline, we are going to use the `existenz_api_fetcher` package.\n",
    "\n",
    "## Requirements\n",
    "To run this notebook you will need the following python packages:\n",
    "```\n",
    "numpy\n",
    "pandas\n",
    "sklearn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c956b170-4344-4168-9971-a0def392edfa",
   "metadata": {},
   "source": [
    "Let's assume that we want our neural network to figure out the relationship between the river flow and the river height, using the data from the Aare river in Bern, Switzerland.\n",
    "Let's first import the necessary modules from the `existenz_api_fetcher` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e1276d-120b-48e6-9be7-920b0087404b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api-datasette.konzept.space/existenz-api/smn_locations\n",
      "https://api-datasette.konzept.space/existenz-api/hydro_locations\n"
     ]
    }
   ],
   "source": [
    "from existenz_api_fetcher import locations, hydro, pipelines\n",
    "\n",
    "# Maps to find FOEN station code for the Aare river in Bern\n",
    "locations.maps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f99735-159c-4396-b5ee-884e818057cc",
   "metadata": {},
   "source": [
    "We now merge the dataframes for the river flow and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6463510a-7291-4922-9c28-03423597d5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-19 00:00:00+00:00</th>\n",
       "      <td>1.097500</td>\n",
       "      <td>519.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 00:00:00+00:00</th>\n",
       "      <td>1.086690</td>\n",
       "      <td>519.104859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-21 00:00:00+00:00</th>\n",
       "      <td>1.036809</td>\n",
       "      <td>519.099645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-22 00:00:00+00:00</th>\n",
       "      <td>0.988881</td>\n",
       "      <td>519.097692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 00:00:00+00:00</th>\n",
       "      <td>0.972979</td>\n",
       "      <td>519.096170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-17 00:00:00+00:00</th>\n",
       "      <td>1.314545</td>\n",
       "      <td>519.120441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-18 00:00:00+00:00</th>\n",
       "      <td>1.203236</td>\n",
       "      <td>519.112379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-19 00:00:00+00:00</th>\n",
       "      <td>1.146044</td>\n",
       "      <td>519.108162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-19 11:12:03.991103+00:00</th>\n",
       "      <td>1.155896</td>\n",
       "      <td>519.108925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-19 11:12:04.309779+00:00</th>\n",
       "      <td>1.155896</td>\n",
       "      <td>519.108925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>733 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      flow      height\n",
       "DateTime                                              \n",
       "2020-10-19 00:00:00+00:00         1.097500  519.107500\n",
       "2020-10-20 00:00:00+00:00         1.086690  519.104859\n",
       "2020-10-21 00:00:00+00:00         1.036809  519.099645\n",
       "2020-10-22 00:00:00+00:00         0.988881  519.097692\n",
       "2020-10-23 00:00:00+00:00         0.972979  519.096170\n",
       "...                                    ...         ...\n",
       "2022-10-17 00:00:00+00:00         1.314545  519.120441\n",
       "2022-10-18 00:00:00+00:00         1.203236  519.112379\n",
       "2022-10-19 00:00:00+00:00         1.146044  519.108162\n",
       "2022-10-19 11:12:03.991103+00:00  1.155896  519.108925\n",
       "2022-10-19 11:12:04.309779+00:00  1.155896  519.108925\n",
       "\n",
       "[733 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pipelines.merge(hydro.flow('2159'), hydro.height('2159'))\n",
    "df.columns = ['flow', 'height']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffac04b3-25aa-4ae3-ab71-4af7907e4219",
   "metadata": {},
   "source": [
    "A data pipeline allows for the automated ingestion, batch processing and storage of data which is going to be used for data science projects and research. In this tutorial, we are focusing on the preprocessing part.\n",
    "In our case, three processing operations are needed before being able to train a LSTM neural network:\n",
    "1) Splitting the raw data into training, validation and testing data\n",
    "2) Standardizing the data by making it more robust to outliers (flood events for example)\n",
    "3) Creating sequences to feed into the neural network\n",
    "\n",
    "We can create a class with a method for each one of these processing operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61131390-1d30-4005-b506-856c6c7feb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create pipeline class\n",
    "class LSTMPipeline(RobustScaler):\n",
    "    \n",
    "    \n",
    "    # Split DataFrame into train, validation and test data\n",
    "    def split(self, df):\n",
    "        \n",
    "        train_size = int(len(df) * 0.7)\n",
    "        validation_size = int(len(df) * 0.2)\n",
    "        test_size = len(df) - train_size - validation_size\n",
    "        \n",
    "        train, validation, test = df.iloc[0:train_size], df.iloc[0:validation_size], df.iloc[train_size+validation_size:len(df)]\n",
    "        print(f\"Shape of training data: {train.shape}\\n\"\n",
    "              f\"Shape of validation data: {validation.shape}\\n\"\n",
    "              f\"Shape of test data: {test.shape}\\n\")\n",
    "        \n",
    "        return train, validation, test\n",
    "    \n",
    "    \n",
    "    # Preprocess data by scaling\n",
    "    def scale(self, train_df, test_df):\n",
    "        \n",
    "        w_columns = ['flow']\n",
    "        w_transformer = RobustScaler()\n",
    "        \n",
    "        w_transformer = w_transformer.fit(train_df[w_columns].to_numpy())\n",
    "        train_df.loc[:, w_columns] = w_transformer.transform(\n",
    "          train_df[w_columns].to_numpy()\n",
    "        )\n",
    "        \n",
    "        test_df.loc[:, w_columns] = w_transformer.transform(\n",
    "          test_df[w_columns].to_numpy()\n",
    "        )\n",
    "\n",
    "        flow_transformer = RobustScaler()\n",
    "        flow_transformer = flow_transformer.fit(train_df[['height']])\n",
    "        train_df['height'] = flow_transformer.transform(train_df[['height']])\n",
    "        test_df['height'] = flow_transformer.transform(test_df[['height']])\n",
    "    \n",
    "    \n",
    "    # Function to prepare sequences\n",
    "    def create_dataset(self, X, y, time_steps):\n",
    "        \n",
    "        Xs, ys = [], []\n",
    "        for i in range(len(X) - time_steps):\n",
    "            v = X.iloc[i:(i + time_steps)].values\n",
    "            Xs.append(v)\n",
    "            ys.append(y.iloc[i + time_steps])\n",
    "            \n",
    "        return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdb4369-c703-4c5a-b142-9fdde502ccd5",
   "metadata": {},
   "source": [
    "We can now create an instance of our pipeline class and use its functions to process our Aare river data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a19558e0-3646-4ff3-92a4-528703e3a2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (513, 2)\n",
      "Shape of validation data: (146, 2)\n",
      "Shape of test data: (74, 2)\n",
      "\n",
      "Shape of flow training data: (503, 10, 2)\n",
      "Shape of height training data: (503,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # Removes false positive SettingWithCopyWarning\n",
    "\n",
    "# Instantiate pipeline class\n",
    "pipeline = LSTMPipeline()\n",
    "\n",
    "train, validation, test = pipeline.split(df)\n",
    "pipeline.scale(train, test)\n",
    "X_train, y_train = pipeline.create_dataset(train, train.flow, time_steps=10)\n",
    "print(f\"Shape of flow training data: {X_train.shape}\\n\"\n",
    "      f\"Shape of height training data: {y_train.shape} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c31a1-7606-44a6-8eb8-4c1345786ae3",
   "metadata": {},
   "source": [
    "All is now ready to feed our data to a LSTM neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
